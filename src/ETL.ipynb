{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2b8c70a-84fc-4530-a1d7-4c6c2fc94aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./UTILS/modules.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9ed663b-93e5-4767-9c25-ec216f9543d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToSilver():\n",
    "    #data cleaning functions\n",
    "    def __init__(self, PATH):\n",
    "        ## ADD BAD RECORD PATH PERMISSIVE\n",
    "        self.df = spark.read.format(\"csv\").option(\"Header\",True).option(\"inferSchema\",True).load(PATH)\n",
    "\n",
    "    def nullHandling(self):\n",
    "        '''\n",
    "            Function responsible to handle nulls\n",
    "            int: 0\n",
    "            string: NA\n",
    "            datetime: 1900-01-01\n",
    "        '''\n",
    "        \n",
    "        string_col = [col[0] for col in self.df.dtypes if col[1].startswith('string')]\n",
    "        int_col = [col[0] for col in self.df.dtypes if col[1].startswith('int')]\n",
    "        timestamp_col = [col[0] for col in self.df.dtypes if col[1].startswith('timestamp')]\n",
    "        \n",
    "        return self.df.fillna('NA', subset = string_col)\\\n",
    "                .fillna(0, subset = int_col).fillna('1900-01-01',subset = timestamp_col)\n",
    "        \n",
    "    def dropColumns(self,df,columns):\n",
    "        '''\n",
    "            Parameters\n",
    "                df: Dataframe\n",
    "                columns: Column list to select\n",
    "        '''\n",
    "        df1 = df.select(columns).drop_duplicates()\n",
    "        return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ac84e0e-36a1-4721-9bca-ae2abef325bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToGold():\n",
    "    #data cleaning functions\n",
    "    def __init__(self,path):\n",
    "\n",
    "        self.primary_person = read_parquet(path['PRIMARY_PERSON_USE_PATH'])\n",
    "        self.units = read_parquet(path['UNITS_USE_PATH'])\n",
    "        self.charges = read_parquet(path['CHARGES_USE_PATH'])\n",
    "        self.endorse = read_parquet(path['ENDORSE_USE_PATH'])\n",
    "        self.damages = read_parquet(path['DAMAGES_USE_PATH'])\n",
    "        self.restrict = read_parquet(path['RESTRICT_USE_PATH'])\n",
    "       \n",
    "   \n",
    "    def accCountMalesKilled(self,path):\n",
    "        \"\"\"\n",
    "            Saves the output dataframe at the GOLD directory.\n",
    "            Parameter: -\n",
    "            Returns:   DataFrame of CRASH_IDs where male death count > 2\n",
    "        \"\"\"\n",
    "        \n",
    "        primary_person = self.primary_person.filter((col('PRSN_GNDR_ID')=='MALE')&(col('PRSN_INJRY_SEV_ID')=='KILLED'))\\\n",
    "                            .groupby(col('CRASH_ID')).sum('DEATH_CNT')    \n",
    "        result = primary_person.filter(col('sum(DEATH_CNT)')>2).select('CRASH_ID')\n",
    "        try:\n",
    "            write_df_to_csv(result,path+'01_male_klld_acc')\n",
    "        except(e):\n",
    "            pass\n",
    "        return result\n",
    "\n",
    "    \n",
    "    def twoWheelerCrashes(self,path):\n",
    "        \"\"\"\n",
    "            Saves the output dataframe at the GOLD directory.\n",
    "            Parameter: -\n",
    "            Returns:   DataFrame of distinct MOTORCYCLE Vehicle IDs \n",
    "                        that were charged during a crash\n",
    "        \"\"\"\n",
    "        units = self.units.where(col('VEH_BODY_STYL_ID').contains('MOTORCYCLE'))\\\n",
    "                    .select('CRASH_ID','VIN').distinct()\n",
    "        \n",
    "        charges = self.charges.select('CRASH_ID').distinct()\n",
    "        result = units.join(charges,on='CRASH_ID',how='inner').select('VIN').distinct()\n",
    "        \n",
    "        \n",
    "        write_df_to_csv(result,path+'02_two_whlr_chrgd')\n",
    "        \n",
    "        return result\n",
    "\n",
    "\n",
    "    def carMakersAirBags(self,path):\n",
    "        \"\"\"\n",
    "            Saves the output dataframe at the GOLD directory.\n",
    "            Parameter: -\n",
    "            Returns:   Returns dataframe with top 5 Car Makers\n",
    "                        when during the airbags did not deploy \n",
    "                        during the accident.\n",
    "        \"\"\"\n",
    "        primary_person = self.primary_person.filter((col('PRSN_INJRY_SEV_ID')=='KILLED')\n",
    "                                                    &(col('PRSN_AIRBAG_ID')=='NOT DEPLOYED'))\\\n",
    "                                            .select('CRASH_ID').distinct()\n",
    "        \n",
    "        units = self.units.filter((~col(\"VEH_MAKE_ID\").isin([\"NA\",\"UNKNOWN\"])))\\\n",
    "                          .select('CRASH_ID','VEH_MAKE_ID').distinct()\n",
    "\n",
    "        result = primary_person.join(units, on ='CRASH_ID',how='inner')\\\n",
    "                                .select(units['*'])\\\n",
    "                                .groupby('VEH_MAKE_ID').count()\\\n",
    "                                .orderBy(col('count').desc()).limit(5)\n",
    "        \n",
    "        write_df_to_csv(result,path+'03_car_arbgs_dth')\n",
    "        return result\n",
    "\n",
    "    def hitAndRun(self,path):\n",
    "        \"\"\"\n",
    "            Saves the output dataframe at the GOLD directory.\n",
    "            Parameter: -\n",
    "            Returns:   Returns dataframe with car VIN\n",
    "                        which were booked for hit & run, having valid licensed.\n",
    "        \"\"\"\n",
    "        units = self.units.filter(col('VEH_HNR_FL')=='Y').select('CRASH_ID','VIN').distinct()\n",
    "        primary_person = self.primary_person.filter((col('DRVR_LIC_TYPE_ID')\\\n",
    "                                                     .isin(['DRIVER LICENSE'\n",
    "                                                            ,'COMMERCIAL DRIVER LIC.'\n",
    "                                                            ,'OCCUPATIONAL'])))\\\n",
    "                                            .select('CRASH_ID').distinct()\n",
    "        result = units.join(primary_person,on='CRASH_ID',how='inner').select('VIN').distinct()\n",
    "        \n",
    "        \n",
    "        write_df_to_csv(result,path+'04_car_vin_hnr')\n",
    " \n",
    "        return result\n",
    "\n",
    "    def stateWithNoFemaleCrashes(self,path):\n",
    "        \"\"\"\n",
    "            Saves the output dataframe at the GOLD directory.\n",
    "            Parameter: -\n",
    "            Returns:   Returns dataframe with car VIN\n",
    "                        which were booked for hit & run, having valid license.\n",
    "        \"\"\"\n",
    "        primary_person = self.primary_person.filter((col('PRSN_GNDR_ID')!='FEMALE'))\\\n",
    "                                            .select('DRVR_LIC_STATE_ID','CRASH_ID')\\\n",
    "                                            .distinct()\n",
    "        result = primary_person.groupby('DRVR_LIC_STATE_ID').count().orderBy(col('count').desc()).limit(1)\n",
    "        \n",
    "        write_df_to_csv(result,path+'05_no_female_acc_state')\n",
    " \n",
    "        return result\n",
    "\n",
    "    def top3To5VehMakers(self,path):\n",
    "        \"\"\"\n",
    "            Returns DF Top 3rd to 5th VEH_MAKE_IDs that contribute \n",
    "                    to a largest number of injuries including death\n",
    "        \"\"\"\n",
    "        units = self.units.withColumn('TOTAL_INJ',col('TOT_INJRY_CNT')+col('DEATH_CNT'))\\\n",
    "                          .groupby('VEH_MAKE_ID').sum('TOTAL_INJ')\\\n",
    "                          .withColumnRenamed(\"sum(TOTAL_INJ)\",\"TOTAL_INJ\")\\\n",
    "                          .orderBy(col('sum(TOTAL_INJ)').desc())\n",
    "        result = units.limit(5).subtract(units.limit(2))\n",
    "        \n",
    "        write_df_to_csv(result,path+'06_car_mkrs_3to5')\n",
    "        return result\n",
    "\n",
    "    def crashesOnVehAndEth(self,path):\n",
    "        \"\"\"\n",
    "            Returns DF: For all the body styles involved in crashes, \n",
    "                        the top ethnic user group of each unique body style  \n",
    "        \"\"\"\n",
    "        units = self.units.filter(~col('VEH_BODY_STYL_ID').isin(\"UNKNOWN\",\"NA\"))\\\n",
    "                    .select('CRASH_ID','VEH_BODY_STYL_ID').distinct()\n",
    "        \n",
    "        primary_person = self.primary_person.filter(~col('PRSN_ETHNICITY_ID').isin(\"UNKNOWN\",\"NA\"))\\\n",
    "                    .select('CRASH_ID','PRSN_ETHNICITY_ID').distinct()\n",
    "        \n",
    "        result = units.join(primary_person, on = 'CRASH_ID',how='inner')\\\n",
    "                    .groupby('VEH_BODY_STYL_ID','PRSN_ETHNICITY_ID').count()\n",
    "        \n",
    "        windowSpec  = Window.partitionBy(\"VEH_BODY_STYL_ID\").orderBy(col(\"count\").desc())\n",
    "        result = result.withColumn(\"rank\",row_number().over(windowSpec))\\\n",
    "                .withColumnRenamed(\"count\",\"NBR_ACC\").filter(col(\"rank\")=='1')\\\n",
    "                .select('VEH_BODY_STYL_ID','PRSN_ETHNICITY_ID','NBR_ACC')\n",
    "        \n",
    "        write_df_to_csv(result,path+'07_car_styl_acc_eth')\n",
    "        return result\n",
    "\n",
    "    def zipCodes_AlcInfluence_Crashes(self,path):    \n",
    "        \"\"\"\n",
    "            Returns: top 5 ZIP codes where accidents occured under \n",
    "                        the influence of alcohol.\n",
    "        \"\"\"\n",
    "        primary_person = self.primary_person.filter(((col('PRSN_ALC_RSLT_ID')=='Positive') \n",
    "                                                     #& (col('PRSN_TYPE_ID').contains('DRIVER'))\\\n",
    "                                                     & (~col('DRVR_ZIP').isin('NA','UNKNOWN'))))\\\n",
    "                .select('DRVR_ZIP','CRASH_ID').drop_duplicates()\n",
    "        \n",
    "        units = self.units.filter(col('CONTRIB_FACTR_1_ID').contains('ALCOHOL')\\\n",
    "                                 |col('CONTRIB_FACTR_2_ID').contains('ALCOHOL')\\\n",
    "                                 |col('CONTRIB_FACTR_P1_ID').contains('ALCOHOL'))\\\n",
    "                .select('CRASH_ID').drop_duplicates()\n",
    "     \n",
    "        result = primary_person.join(units,on='CRASH_ID',how='full').dropna().drop_duplicates()\n",
    "   \n",
    "        result = result.groupby('DRVR_ZIP').count().orderBy(col('count').desc()).limit(5)\n",
    "        \n",
    "        \n",
    "        write_df_to_csv(result,path+'08_alc_acc_per_zip')\n",
    "        return result\n",
    "\n",
    "\n",
    "    def insAvailCrashes(self,path):\n",
    "        \"\"\"\n",
    "            Returns: CRASH_IDs where insurance was availed\n",
    "                     and damage grade > 4 or no damage done.\n",
    "        \"\"\"\n",
    "        result = self.units.filter(col('FIN_RESP_TYPE_ID').isin(['PROOF OF LIABILITY INSURANCE'\n",
    "                                                                ,'LIABILITY INSURANCE POLICY'\n",
    "                                                                ,'CERTIFICATE OF SELF-INSURANCE'\n",
    "                                                                ,'INSURANCE BINDER'])\n",
    "                                 & ((col('VEH_DMAG_SCL_1_ID') > 'DAMAGED 4')  \n",
    "                                   |(col('VEH_DMAG_SCL_1_ID') == 'NO DAMAGED')\n",
    "                                   |(col('VEH_DMAG_SCL_2_ID') == 'NO DAMAGED')\n",
    "                                   |(col('VEH_DMAG_SCL_2_ID') > 'DAMAGED 4')))\\\n",
    "                .select('CRASH_ID').distinct()\n",
    "        \n",
    "       \n",
    "        write_df_to_csv(result,path+'09_ins_whn_dmag')\n",
    "        return result\n",
    "\n",
    "    def veh_mkrs_spding(self,path):\n",
    "        \"\"\"Determine the Top 5 Vehicle Makes where drivers are \n",
    "            charged with speeding related offences, \n",
    "            has licensed Drivers, used top 10 used vehicle colours \n",
    "            and has car licensed with the Top 25 states \n",
    "            with highest number of offences (to be deduced from the data)\n",
    "        \"\"\"\n",
    "        \n",
    "        primary_person = self.primary_person.filter((col('PRSN_TYPE_ID').contains('DRIVER'))\n",
    "                                                    &(col('DRVR_LIC_TYPE_ID')\\\n",
    "                                                     .isin(['DRIVER LICENSE'\n",
    "                                                            ,'COMMERCIAL DRIVER LIC.'\n",
    "                                                            ,'OCCUPATIONAL'])))\\\n",
    "                                            .select('CRASH_ID','DRVR_LIC_STATE_ID').distinct()\\\n",
    "                                            .filter(~col('DRVR_LIC_STATE_ID').isin(['NA','UNKNOWN']))\\\n",
    "                                            .groupby('DRVR_LIC_STATE_ID').count()\\\n",
    "                                            .orderBy(col('count').desc()).limit(25).select('DRVR_LIC_STATE_ID')\n",
    "        top25states = [i[0] for i in primary_person.collect()]\n",
    "        \n",
    "        crashes_in_25_states = self.primary_person.filter(col('DRVR_LIC_STATE_ID').isin(top25states))\\\n",
    "                                                  .select('CRASH_ID').drop_duplicates()\n",
    "        \n",
    "        units = self.units.select('VEH_COLOR_ID','CRASH_ID').distinct()\\\n",
    "                         .filter(~col('VEH_COLOR_ID').isin(['NA','UNKNOWN']))\\\n",
    "                         .groupby('VEH_COLOR_ID').count()\\\n",
    "                         .orderBy(col('count').desc()).limit(10).select('VEH_COLOR_ID')\n",
    "        \n",
    "        top10clrs = [i[0] for i in units.collect()]\n",
    "        \n",
    "        crashes_in_10_colors = self.units.filter(col('VEH_COLOR_ID').isin(top25states))\\\n",
    "                                                  .select('CRASH_ID').drop_duplicates()\n",
    "        \n",
    "        charges = self.charges.filter((col('CHARGE').contains('SPEED'))).select('CRASH_ID').distinct()\n",
    "        crashes = crashes_in_25_states.union(crashes_in_10_colors).union(charges)\n",
    "        \n",
    "        result = self.units.join(crashes,on='CRASH_ID',how='inner').distinct()\\\n",
    "            .groupby('VEH_MAKE_ID').count()\\\n",
    "            .orderBy(col('count').desc()).limit(5)\n",
    "        \n",
    "       \n",
    "        write_df_to_csv(result,path+'10_veh_mkrs_speeding')\n",
    "        return result                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4579c04-6ee7-4ffb-a4b2-030ac7012497",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark-env",
   "language": "python",
   "name": "pyspark-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
